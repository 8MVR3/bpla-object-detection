# scripts/run_inference.py

import cv2
import numpy as np
import pycuda.driver as cuda
import tensorrt as trt

engine_file = "exports/weights/best.engine"
img_path = "assets/sample.jpg"  # –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞

TRT_LOGGER = trt.Logger()

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–≤–∏–∂–∫–∞
with open(engine_file, "rb") as f, trt.Runtime(TRT_LOGGER) as runtime:
    engine = runtime.deserialize_cuda_engine(f.read())

context = engine.create_execution_context()

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
input_shape = tuple(engine.get_binding_shape(0))
img = cv2.imread(img_path)
img = cv2.resize(img, (input_shape[2], input_shape[1]))
img = img.astype(np.float32) / 255.0
img = np.transpose(img, (2, 0, 1))  # CHW
img = np.expand_dims(img, axis=0)  # NCHW
img = np.ascontiguousarray(img)

# –í—ã–¥–µ–ª—è–µ–º –ø–∞–º—è—Ç—å
d_input = cuda.mem_alloc(img.nbytes)
output_shape = tuple(engine.get_binding_shape(1))
output = np.empty(output_shape, dtype=np.float32)
d_output = cuda.mem_alloc(output.nbytes)

# –ö–æ–ø–∏—Ä—É–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º
cuda.memcpy_htod(d_input, img)
context.execute_v2([int(d_input), int(d_output)])
cuda.memcpy_dtoh(output, d_output)

print("‚úÖ Inference output shape:", output.shape)
print("üî¢ Output sample:", output.ravel()[:10])
